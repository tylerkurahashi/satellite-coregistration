# SpaceNet 9 Challenge: Cross-Modal Satellite Imagery Registration

## 概要
SpaceNet 9は、災害対応における光学画像とSAR（合成開口レーダー）画像のクロスモーダル位置合わせ（コレジストレーション）を対象とした機械学習チャレンジです。

## 1. はじめに

### SpaceNetの背景
- 2016年に設立された、地理空間応用のためのオープンソース機械学習加速を目的とした共同イニシアティブ
- 8回のイノベーションチャレンジを主催、勝利アルゴリズムはすべてオープンソース化
- 参加組織：Maxar、AWS、IEEE-GRSS、Oak Ridge National Laboratory、OGC、Topcoder、UMBRA

### 課題の背景
- 自然災害への迅速な対応が人命と社会インフラへの影響軽減に重要
- 光学画像とSAR画像の位置合わせが災害前後の影響評価に必要
- SAR画像は雲を透過し夜間撮影可能だが、光学画像との位置合わせが困難
- **技術的課題**：異なる撮影ジオメトリによるクロスモーダル位置合わせの困難さ

## 2. データセットとチャレンジ

### データ構成
- **光学画像**：Maxar Open Data Program提供
- **SAR画像**：UMBRA提供
- **対象地域**：地震被災地域（実際の災害対応データセット）
- **タイポイント**：道路交差点等の手動ラベル付き対応点（各AOIあたり約500点）

### データセット分割
- **訓練データセット**：一部AOI（Area of Interest）
- **公開テストデータセット**：ラベル非公開の別AOI
- **プライベートテストデータセット**：最終評価用の第3のAOI

### 評価方法
- 光学画像とSAR画像間のピクセル単位変換の算出
- タイポイント座標変換による空間距離測定で精度評価

### 技術的困難さ
- **SAR画像の特徴**：
  - 物理的特性測定（距離ベース）
  - サイドルッキング撮影によるレイオーバー、フォアショートニング、レーダーシャドウ
  - スペックルノイズ
- **光学画像の特徴**：
  - 化学的特性測定
  - 透視投影撮影

### 関連データセット
- **SEN1-2**：約280,000組のSentinel-1/2画像ペア
- **SARptical**：10,000組の高解像度都市部画像ペア
- **QXS-SAROPT**：20,000組の1m GSD画像ペア
- **SOPatch**：650,000組の画像ペア

## 3. ベースラインアルゴリズム

### 全体構成
1. **シーン位置合わせ**：空間範囲と解像度の統一
2. **学習データ準備**：タイル化とキーポイントヒートマップ生成
3. **キーポイント検出ネットワーク訓練**
4. **推論ワークフロー**：変換推定とピクセルオフセットマップ生成

### 学習フェーズ

#### データ準備
- **タイル作成**：256×256ピクセルのタイル
- **ヒートマップラベル**：標準偏差13ピクセルの2Dガウシアンカーネル
- **2つのデータセット**：
  - 光学キーポイント検出用（光学-SAR画像ペア＋SARキーポイントヒートマップ）
  - SARキーポイント検出用（光学-SAR画像ペア＋光学キーポイントヒートマップ）

#### ネットワークアーキテクチャ
- **U-Net スタイル**：ピクセル単位回帰用
- **2つの独立ネットワーク**：光学キーポイント検出用、SARキーポイント検出用
- **損失関数**：重み付きMSE損失（ピクセルレベル）

#### 学習パラメータ
- **エポック数**：100
- **最適化手法**：Adam（初期学習率1e-4）
- **学習率スケジュール**：30エポック後に1e-2倍
- **GPU**：NVIDIA V100（32GB）

### 推論フェーズ

#### ワークフロー
1. **光学キーポイント検出**：100m間隔の均一グリッドで全光学シーンを処理
2. **SARキーポイント検出**：検出された光学キーポイント周辺でSARキーポイントを検出
3. **変換推定**：RANSACを用いたアフィン変換推定
4. **ピクセルオフセットマップ生成**：各ピクセルのx,y方向シフト量を記述

## 4. 実験結果

### 実験設定
- **データ分割**：80%訓練、20%検証
- **評価指標**：変換された光学キーポイントと対応するSARタイポイント間の平均距離

### 結果

#### アノテーション付きタイポイントによる変換評価
| AOI | 変換前平均距離 | アフィン変換後 | アフィン+RANSAC |
|-----|----------------|----------------|-----------------|
| AOI-1 | 30.22m (84.54px) | 14.24m (39.84px) | 13.14m (37.77px) |
| AOI-2 | 34.96m (85.46px) | 27.88m (68.14px) | 26.31m (64.31px) |

#### 自動化ワークフローの結果
| AOI | 検出光学キーポイント | インライア数 | 平均距離 |
|-----|---------------------|--------------|----------|
| AOI-1 | 840 | 59 | 20.99m (58.72px) |
| AOI-2 | 930 | 81 | 40.68m (99.46px) |

### 結果分析
- **成功事例**：AOI-1では位置合わせが改善
- **課題**：AOI-2では期待した改善が得られず
- **改善の余地**：ベースラインを大幅に上回る性能向上の可能性

## 5. 結論

### 達成目標
- 光学画像とSAR画像のクロスモーダル位置合わせ技術の理解と実装の加速
- 災害対応コミュニティのワークフロー加速への貢献
- 多様なリモートセンシングデータを活用した時間的制約のある分析の支援

### 今後の展開
- チャレンジ結果公開後、勝利アルゴリズムの詳細分析論文を発表予定
- 地震以外の災害（洪水、竜巻、ハリケーン等）への応用可能性

### コードとデータの公開
- GitHubリポジトリ：https://github.com/SpaceNetChallenge/SpaceNet9

## 技術的インサイト

### 従来手法の限界
- **古典的手法**：SIFT等の手作り特徴量はSAR-光学画像マッチングに不適切
- **修正アプローチ**：深層学習と疑似シャム型アーキテクチャの活用

### SpaceNet 9の特徴
- **現実的シナリオ**：大きな画像領域間の詳細な位置合わせ
- **評価方法**：空間変換マップによるタイポイント座標変換と距離測定
- **実用性**：災害対応における実際のデータセットを使用